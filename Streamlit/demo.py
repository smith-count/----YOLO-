import csv
from datetime import datetime
import zipfile
import shutil
import numpy as np
import pandas as pd
from ultralytics import YOLO
from PIL import Image
from io import BytesIO
import os
import threading
import time
import cv2
import streamlit as st
from util import convert_video_with_ffmpeg
import plotly.express as px

# ======================
# è‡ªå®šä¹‰CSSæ ·å¼
# ======================
st.markdown("""
<style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main-container {
        background: linear-gradient(145deg, #f8f9fa 0%, #e9ecef 100%);
        border-radius: 15px;
        padding: 2rem;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }

    /* åŠ¨æ€è¾¹æ¡†åŠ¨ç”» */
    @keyframes border-glow {
        0% { box-shadow: 0 0 10px rgba(76,175,80,0.3); }
        50% { box-shadow: 0 0 15px rgba(33,150,243,0.5); }
        100% { box-shadow: 0 0 10px rgba(76,175,80,0.3); }
    }

    .section-card {
        border: 1px solid #dee2e6;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        background: white;
        animation: border-glow 3s ease-in-out infinite;
    }

    /* æŒ‰é’®ç¾åŒ– */
    .stButton>button {
        background: linear-gradient(45deg, #4CAF50, #2196F3) !important;
        color: white !important;
        border: none !important;
        border-radius: 25px !important;
        padding: 0.8rem 1.5rem !important;
        font-weight: 600 !important;
        transition: all 0.3s !important;
    }

    .stButton>button:hover {
        transform: scale(1.05);
        box-shadow: 0 4px 15px rgba(0,0,0,0.2) !important;
    }

    /* ä¾§è¾¹æ ç¾åŒ– */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #2c3e50, #34495e) !important;
        box-shadow: 2px 0 15px rgba(0,0,0,0.1);
    }

    .sidebar-title {
        color: #fff !important;
        font-size: 1.5rem !important;
        padding: 1rem 0;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–å…¨å±€å˜é‡
MODEL_PATHS = {
    "YOLOv11":"D:\Python\graduate_design\Model\yolo11n.pt",
    "YOLO_detect_animals":r"D:\Python\graduate_design\Model\runs\train\exp\weights\best.pt", #
}

current_model = YOLO(r"D:\Python\graduate_design\Model\yolo11n.pt")# é»˜è®¤
conf_threshold = 0
iou_threshold = 0
detection_data = []
detections_df = None
speed_df = None
flag = False # ç”¨äºæ£€æµ‹æœ‰æ— å›¾åƒ
target_class = []


def process_yolo_results(results, class_list=None, conf_thres=0.1):
    global flag
    # """
    # å¤„ç†YOLOç»“æœå¹¶è¿”å›å¯ç›´æ¥æ˜¾ç¤ºçš„å›¾åƒ
    # :param results: YOLOæ£€æµ‹ç»“æœ(å•ä¸ªResultså¯¹è±¡)
    # :param class_list: è¦æ˜¾ç¤ºçš„ç±»åˆ«åˆ—è¡¨
    # :param conf_thres: ç½®ä¿¡åº¦é˜ˆå€¼
    # :return: å¯ç›´æ¥æ˜¾ç¤ºçš„numpyæ•°ç»„å›¾åƒ(BGRæ ¼å¼)
    # """
    # 1. ç»“æœè¿‡æ»¤
    if class_list is not None:
        names = results.names
        keep_idx = [
            i for i, box in enumerate(results.boxes)
            if (names[int(box.cls)] in class_list) and (float(box.conf) >= conf_thres)
        ]
        results.boxes = results.boxes[keep_idx]
        if hasattr(results, 'masks') and results.masks is not None:
            results.masks = results.masks[keep_idx]
        if hasattr(results, 'keypoints') and results.keypoints is not None:
            results.keypoints = results.keypoints[keep_idx]

    if len(results.boxes)==0 :
        flag = False
    # 2. å®‰å…¨å›¾åƒè½¬æ¢
    plotted_img = results.plot()

    # å¤„ç†ä¸åŒè¿”å›ç±»å‹
    if isinstance(plotted_img, Image.Image):
        # PIL.Imageè½¬numpyæ•°ç»„
        img_np = np.array(plotted_img)
        # ç¡®ä¿æ˜¯3é€šé“(RGBæˆ–BGR)
        if img_np.ndim == 2:  # ç°åº¦å›¾
            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
        elif img_np.shape[2] == 4:  # RGBA
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)
        else:  # RGB
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    else:  # å·²ç»æ˜¯numpyæ•°ç»„
        img_np = plotted_img
        if img_np.ndim == 2:  # ç°åº¦å›¾
            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
        elif img_np.shape[2] == 4:  # RGBA
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)
        elif img_np.shape[2] == 3:  # ç¡®ä¿æ˜¯BGR
            pass  # å‡è®¾å·²ç»æ˜¯BGR

    return img_np

# åŠ è½½æ¨¡å‹
def load_model(model_name):
    global current_model
    model_path = MODEL_PATHS.get(model_name)
    if not model_path:
        st.error("æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼")
        return None
    try:
        model = YOLO(model_path)
        st.success(f"æˆåŠŸåŠ è½½æ¨¡å‹ï¼š{model_name}")
        return model
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{e}")
        return None

def yolo_results_to_dataframe(results):
    """
    å°†YOLOæ£€æµ‹ç»“æœè½¬æ¢ä¸ºç»“æ„åŒ–DataFrame
    """
    global detection_data
    result = results[0]

    try:
        for i, box in enumerate(result.boxes, 1):
            detection_data.append({
            "åºå·": i,
            "ç±»åˆ«ID": int(box.cls.item()),
            "ç±»åˆ«åç§°": result.names[int(box.cls.item())],
            "ç½®ä¿¡åº¦": float(box.conf.item()),
            "x1": round(box.xyxy[0][0].item()),
            "y1": round(box.xyxy[0][1].item()),
            "x2": round(box.xyxy[0][2].item()),
            "y2": round(box.xyxy[0][3].item()),
            "å®½åº¦": round(box.xyxy[0][2].item() - box.xyxy[0][0].item()),
            "é«˜åº¦": round(box.xyxy[0][3].item() - box.xyxy[0][1].item())
            })
    except Exception as e:
            st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
            return

    return pd.DataFrame(detection_data), pd.DataFrame([result.speed])
# å›¾ç‰‡æ£€æµ‹
def image_detection():
    global current_model
    global detection_data
    global detections_df
    global speed_df
    global flag
    global iou_threshold
    global conf_threshold

    st.header("å›¾ç‰‡æ£€æµ‹")

    # ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶",
                                   type=["jpg", "jpeg", "png"],
                                   label_visibility="visible")

    if uploaded_file:
        flag = True
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)

        # æ‰“å¼€åŸå§‹å›¾åƒ
        original_image = Image.open(uploaded_file)
        img_array = np.array(original_image)
        img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        # å·¦ä¾§æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
        with col1:
            st.subheader("åŸå§‹å›¾ç‰‡")
            st.image(original_image,  use_container_width=True)

        # å³ä¾§æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»“æœ
        with col2:
            st.subheader("æ£€æµ‹ç»“æœ")

            with st.spinner("YOLOæ¨¡å‹æ­£åœ¨å¤„ç†ä¸­..."):
                try:
                    # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ¨ç†
                    results = current_model(
                        source=img_cv,
                        conf=conf_threshold,
                        iou=iou_threshold,
                        save=False
                    )

                    process_yolo_results(results[0],class_list=target_class,
                                                    )
                    annotated_image = results[0].plot()
                    annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
                    st.image(annotated_image, use_container_width=True)

                    # è½¬æ¢ç»“æœä¸ºDataFrame
                    if hasattr(results[0], 'boxes'):
                        detections_df, speed_df = yolo_results_to_dataframe(results)

                    # æ·»åŠ ä¸‹è½½åŠŸèƒ½
                    buffered = BytesIO()
                    Image.fromarray(annotated_image).save(buffered, format="JPEG")
                    st.download_button(
                        label="ğŸ“¥ å¯¼å‡ºæ£€æµ‹å›¾ç‰‡",
                        data=buffered.getvalue(),
                        file_name=f"detection_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg",
                        mime="image/jpeg",
                        type="primary"
                    )

                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                    return

        # ä¸‹æ–¹æ˜¾ç¤ºè¯¦ç»†æ•°æ®
        st.divider()
        st.subheader("æ£€æµ‹æ•°æ®è¯¦æƒ…")

        if flag :
            # æ ¼å¼åŒ–è¡¨æ ¼
            display_df = detections_df.copy()
            display_df['ç½®ä¿¡åº¦'] = display_df['ç½®ä¿¡åº¦'].apply(lambda x: f"{x:.2%}")

            # äº¤äº’å¼è¡¨æ ¼
            st.dataframe(
                display_df[['åºå·', 'ç±»åˆ«åç§°', 'ç½®ä¿¡åº¦', 'x1', 'y1', 'x2', 'y2']],
                column_config={
                    "ç½®ä¿¡åº¦": st.column_config.ProgressColumn(
                        min_value=0,
                        max_value=1,
                        format="%.2f%%"
                    )
                },
                hide_index=True,
                use_container_width=True
            )

            # ç»Ÿè®¡ä¿¡æ¯
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("æ£€æµ‹ç›®æ ‡æ€»æ•°", len(detections_df))
            with col_stat2:
                st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{detections_df['ç½®ä¿¡åº¦'].mean():.2%}")

            # ç±»åˆ«åˆ†å¸ƒ
            st.subheader("ç±»åˆ«åˆ†å¸ƒ")
            st.bar_chart(detections_df['ç±»åˆ«åç§°'].value_counts())

            # å¤„ç†é€Ÿåº¦å’Œæ•°æ®ä¸‹è½½
            with st.expander("é«˜çº§é€‰é¡¹"):
                tab1, tab2 = st.tabs(["æ€§èƒ½æŒ‡æ ‡", "æ•°æ®å¯¼å‡º"])
                with tab1:
                    st.dataframe(
                        speed_df.rename(columns={
                            'preprocess': 'é¢„å¤„ç†(ms)',
                            'inference': 'æ¨ç†(ms)',
                            'postprocess': 'åå¤„ç†(ms)'
                        }),
                        use_container_width=True
                    )
                with tab2:
                    st.download_button(
                        label="ğŸ“Š å¯¼å‡ºæ£€æµ‹æ•°æ®(CSV)",
                        data=detections_df.to_csv(index=False).encode('utf-8'),
                        file_name="detection_data.csv",
                        mime="text/csv"
                    )

        # æ§åˆ¶å°è¾“å‡ºï¼ˆè°ƒè¯•ç”¨ï¼‰
        #     print("==== æ£€æµ‹ç»“æœ ====")
        #     print(detections_df[['åºå·', 'ç±»åˆ«åç§°', 'ç½®ä¿¡åº¦', 'x1', 'y1', 'x2', 'y2']].to_string(index=False))
        #     print("\n==== å¤„ç†é€Ÿåº¦ (ms) ====")
        #     print(speed_df.to_string(index=False))



def video_detection():
    global current_model
    global detection_data
    global conf_threshold
    global iou_threshold
    st.header("ğŸ¥ è§†é¢‘æ£€æµ‹ç³»ç»Ÿ")

    # # åœ¨ä¾§è¾¹æ æ·»åŠ ç±»åˆ«é€‰æ‹©åŠŸèƒ½
    # with st.sidebar.expander("ğŸ” æ£€æµ‹ç±»åˆ«è®¾ç½®", expanded=True):
    #     # è·å–æ¨¡å‹æ”¯æŒçš„ç±»åˆ«åˆ—è¡¨
    #     class_options = list(current_model.names.values())
    #     selected_classes = st.multiselect(
    #         "é€‰æ‹©è¦æ£€æµ‹çš„ç±»åˆ«",
    #         options=class_options,
    #         default=class_options[:3],  # é»˜è®¤é€‰æ‹©å‰3ä¸ªç±»åˆ«
    #         help="é€‰æ‹©éœ€è¦æ£€æµ‹çš„ç›®æ ‡ç±»åˆ«"
    #     )

    # ä½¿ç”¨å®¹å™¨åˆ’åˆ†ä¸»è¦åŠŸèƒ½åŒºåŸŸ
    upload_container = st.container(border=True)
    with upload_container:
        # ä¸Šä¼ åŒºåŸŸ
        st.subheader("1. è§†é¢‘ä¸Šä¼ ")
        uploaded_file = st.file_uploader("é€‰æ‹©å¾…æ£€æµ‹è§†é¢‘æ–‡ä»¶",
                                         type=["mp4", "avi", "mov"],
                                         label_visibility="collapsed",
                                         help="æ”¯æŒ MP4/AVI/MOV æ ¼å¼ï¼Œæœ€å¤§æ–‡ä»¶å¤§å° 500MB")

    if uploaded_file:
        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_video_path = "temp_uploaded_video.mp4"
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # è§†é¢‘é¢„è§ˆå’Œå¤„ç†åŒºåŸŸ
        process_container = st.container(border=True)
        with process_container:
            st.subheader("2. è§†é¢‘å¤„ç†")

            # åˆ›å»ºå¯¹æ¯”å¸ƒå±€
            col1, col2 = st.columns([0.45, 0.55], gap="large")

            with col1:
                # åŸå§‹è§†é¢‘é¢„è§ˆ
                st.markdown("**åŸå§‹è§†é¢‘é¢„è§ˆ**")
                st.video(temp_video_path)

            with col2:
                # å¤„ç†çŠ¶æ€åŒºåŸŸ
                status_col1, status_col2 = st.columns([0.7, 0.3])
                with status_col1:
                    st.markdown("**å¤„ç†çŠ¶æ€**")
                    progress_placeholder = st.empty()

        # å¤„ç†ç»“æœåŒºåŸŸ
        processed_video_placeholder = st.empty()
        export_placeholder = st.empty()
        visualization_placeholder = st.empty()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join("temp_results", "processed_video")
        os.makedirs(output_dir, exist_ok=True)
        output_video_name = "output_" + os.path.basename(temp_video_path)
        processed_temp_video_path = os.path.join(output_dir, "temp_processed_video.avi")
        final_processed_video_path = os.path.join(output_dir, output_video_name)
        detection_csv_path = os.path.join(output_dir, "detection_results.csv")

        try:
            # è·å–è§†é¢‘ä¿¡æ¯
            cap = cv2.VideoCapture(temp_video_path)
            if not cap.isOpened():
                raise ValueError("æ— æ³•æ‰“å¼€ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶")
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()

            # åˆå§‹åŒ–æ£€æµ‹ç»“æœæ”¶é›†
            frame_timestamps = []
            lock = threading.Lock()

            def process_video():
                nonlocal processed_frames
                try:
                    # åˆå§‹åŒ–CSVæ–‡ä»¶
                    with open(detection_csv_path, mode='w', newline='') as csv_file:
                        fieldnames = ['frame_num', 'timestamp', 'class', 'confidence', 'x1', 'y1', 'x2', 'y2']
                        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
                        writer.writeheader()

                    # ä½¿ç”¨YOLOè¿›è¡Œè§†é¢‘æ£€æµ‹
                    results = current_model.track(
                        source=temp_video_path,
                        conf=conf_threshold,
                        iou=iou_threshold,
                        stream=True,
                        imgsz=(width, height),
                        save=False,
                        project=None,
                        name=None,
                        verbose=False
                    )

                    # æ‰‹åŠ¨ä¿å­˜å¤„ç†åçš„è§†é¢‘
                    fourcc = cv2.VideoWriter_fourcc(*'XVID')
                    out = cv2.VideoWriter(processed_temp_video_path, fourcc, fps, (width, height))

                    for frame_idx, frame_result in enumerate(results):
                        # è·å–å½“å‰å¸§æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                        current_time = frame_idx / fps

                        # ç­›é€‰æŒ‡å®šç±»åˆ«çš„æ£€æµ‹ç»“æœ
                        if target_class:  # å¦‚æœç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šç±»åˆ«
                            keep_idx = [
                                i for i, box in enumerate(frame_result.boxes)
                                if current_model.names[int(box.cls)] in target_class
                            ]
                            frame_result.boxes = frame_result.boxes[keep_idx]
                            if hasattr(frame_result, 'masks') and frame_result.masks is not None:
                                frame_result.masks = frame_result.masks[keep_idx]
                            if hasattr(frame_result, 'keypoints') and frame_result.keypoints is not None:
                                frame_result.keypoints = frame_result.keypoints[keep_idx]

                        # ç»˜åˆ¶æ£€æµ‹ç»“æœåˆ°å¸§
                        processed_frame = frame_result.plot()
                        out.write(processed_frame)

                        # æ”¶é›†æ£€æµ‹æ•°æ®ï¼ˆåªè®°å½•é€‰ä¸­çš„ç±»åˆ«ï¼‰
                        for detection in frame_result.boxes:
                            class_id = int(detection.cls)
                            class_name = current_model.names[class_id]
                            conf = float(detection.conf)
                            bbox = detection.xyxy[0].tolist()

                            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°æ•°æ®
                            with lock:
                                detection_data.append({
                                    'frame_num': frame_idx,
                                    'timestamp': current_time,
                                    'class': class_name,
                                    'confidence': conf,
                                    'x1': bbox[0],
                                    'y1': bbox[1],
                                    'x2': bbox[2],
                                    'y2': bbox[3]
                                })
                                processed_frames = frame_idx + 1
                                frame_timestamps.append(current_time)

                        # æ¯å¤„ç†10å¸§æˆ–ç»“æŸæ—¶ä¿å­˜ä¸€æ¬¡CSV
                        if frame_idx % 10 == 0 or frame_idx == total_frames - 1:
                            with lock:
                                with open(detection_csv_path, mode='a', newline='') as csv_file:
                                    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
                                    writer.writerows(detection_data[-10:])

                    out.release()
                except Exception as e:
                    st.error(f"è§†é¢‘å¤„ç†å†…éƒ¨é”™è¯¯: {str(e)}")

            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            processed_frames = 0
            process_thread = threading.Thread(target=process_video)
            process_thread.start()

            # å®æ—¶æ›´æ–°è¿›åº¦
            while process_thread.is_alive():
                with lock:
                    progress = min(100, int((processed_frames / total_frames) * 100) if total_frames > 0 else 0)
                progress_placeholder.progress(
                    progress,
                    text=f"â– å¤„ç†è¿›åº¦: {progress}% | å·²å¤„ç† {processed_frames}/{total_frames} å¸§"
                )
                time.sleep(0.1)

            process_thread.join()

            # è§†é¢‘æ ¼å¼è½¬æ¢
            if os.path.exists(processed_temp_video_path):
                convert_video_with_ffmpeg(processed_temp_video_path, final_processed_video_path)

            # æ˜¾ç¤ºå¤„ç†ç»“æœ
            with process_container:
                with col2:
                    if os.path.exists(final_processed_video_path):
                        processed_video_placeholder.markdown("**æ£€æµ‹ç»“æœé¢„è§ˆ**")
                        processed_video_placeholder.video(final_processed_video_path)

                        # å¯¼å‡ºæŒ‰é’®
                        with export_placeholder:
                            col_export1, col_export2 = st.columns(2)
                            with col_export1:
                                with open(final_processed_video_path, "rb") as f:
                                    st.download_button(
                                        label="â¬‡ï¸ å¯¼å‡ºç»“æœè§†é¢‘",
                                        data=f,
                                        file_name=output_video_name,
                                        mime="video/mp4",
                                        use_container_width=True,
                                        type="primary"
                                    )
                            with col_export2:
                                with open(detection_csv_path, "rb") as f:
                                    st.download_button(
                                        label="ğŸ“Š å¯¼å‡ºæ£€æµ‹æ•°æ®(CSV)",
                                        data=f,
                                        file_name="detection_results.csv",
                                        mime="text/csv",
                                        use_container_width=True
                                    )

            # æ•°æ®å¯è§†åŒ–ï¼ˆåªæ˜¾ç¤ºé€‰ä¸­çš„ç±»åˆ«ï¼‰
            if os.path.exists(detection_csv_path):
                with visualization_placeholder.container(border=True):
                    st.subheader("3. æ£€æµ‹æ•°æ®åˆ†æ")

                    # åŠ è½½æ£€æµ‹æ•°æ®
                    df = pd.read_csv(detection_csv_path)

                    # ç­›é€‰é€‰ä¸­çš„ç±»åˆ«
                    if target_class:
                        df = df[df['class'].isin(target_class)]

                    if not df.empty:
                        # åˆ›å»ºå¯è§†åŒ–é€‰é¡¹å¡
                        tab1, tab2, tab3 = st.tabs(["ç±»åˆ«åˆ†å¸ƒ", "æ—¶é—´è¶‹åŠ¿", "ç©ºé—´åˆ†å¸ƒ"])

                        with tab1:
                            st.markdown("**æ£€æµ‹ç±»åˆ«ç»Ÿè®¡**")
                            species_counts = df['class'].value_counts().reset_index()
                            species_counts.columns = ['Class', 'Count']
                            fig1 = px.bar(species_counts,
                                          x='Class',
                                          y='Count',
                                          color='Class',
                                          text='Count')
                            st.plotly_chart(fig1, use_container_width=True)

                        with tab2:
                            st.markdown("**æ£€æµ‹ç»“æœæ—¶é—´åˆ†å¸ƒ**")
                            df['time_interval'] = (df['timestamp'] // 5) * 5  # 5ç§’é—´éš”åˆ†ç»„
                            time_dist = df.groupby(['time_interval', 'class']).size().reset_index(name='count')
                            fig2 = px.line(time_dist,
                                           x='time_interval',
                                           y='count',
                                           color='class',
                                           markers=True)
                            fig2.update_xaxes(title="æ—¶é—´ (ç§’)")
                            fig2.update_yaxes(title="æ£€æµ‹æ•°é‡")
                            st.plotly_chart(fig2, use_container_width=True)

                        with tab3:
                            st.markdown("**æ£€æµ‹ç›®æ ‡ç©ºé—´åˆ†å¸ƒ**")
                            fig3 = px.scatter(df,
                                              x='x1',
                                              y='y1',
                                              color='class',
                                              size='confidence',
                                              hover_data=['frame_num', 'confidence'])
                            fig3.update_xaxes(range=[0, width])
                            fig3.update_yaxes(range=[height, 0])  # åè½¬Yè½´åŒ¹é…å›¾åƒåæ ‡
                            st.plotly_chart(fig3, use_container_width=True)
                    else:
                        st.warning("æœªæ£€æµ‹åˆ°é€‰å®šç±»åˆ«çš„ç›®æ ‡")

        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", icon="ğŸš¨")

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
            if os.path.exists(processed_temp_video_path):
                os.remove(processed_temp_video_path)


def real_time_detection():
    """å®æ—¶ç›®æ ‡æ£€æµ‹å‡½æ•°"""
    st.title("å®æ—¶ç›®æ ‡æ£€æµ‹")
    global current_model
    global conf_threshold
    global iou_threshold


    start_button = st.button("å¼€å§‹æ£€æµ‹")
    stop_button = st.button("åœæ­¢æ£€æµ‹")

    if start_button:
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            st.error("æ— æ³•æ‰“å¼€è§†é¢‘æº")
            return

        st_frame = st.empty()  # ç”¨äºåŠ¨æ€æ›´æ–°ç”»é¢çš„å ä½ç¬¦
        stats_placeholder = st.empty()  # ç»Ÿè®¡ä¿¡æ¯å ä½ç¬¦

        while cap.isOpened() and not stop_button:
            success, frame = cap.read()
            if not success:
                st.warning("è§†é¢‘æµç»“æŸ")
                break

            # æ‰§è¡Œæ£€æµ‹
            start_time = time.time()
            results = current_model(frame,
                            conf=conf_threshold,
                            iou=iou_threshold,
                            verbose=False)

            # è®¡ç®—FPS
            fps = 1 / (time.time() - start_time + 1e-9)

            # ç»˜åˆ¶ç»“æœ
            annotated_frame = results[0].plot()
            annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            num_objects = len(results[0].boxes)
            stats_text = f"""
            **æ£€æµ‹ç»Ÿè®¡**  
            â€¢ ç›®æ ‡æ•°é‡: {num_objects}  
            â€¢ ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold:.2f}  
            â€¢ å®æ—¶FPS: {fps:.1f}  
            """

            # æ›´æ–°ç•Œé¢
            st_frame.image(annotated_frame, caption="å®æ—¶æ£€æµ‹ç”»é¢", use_container_width=True)
            stats_placeholder.markdown(stats_text)

            # æ§åˆ¶å¸§ç‡ (é»˜è®¤30FPS)
            time.sleep(1 / 30)

        cap.release()
        cv2.destroyAllWindows()

def model_usage():
    global current_model
    global iou_threshold
    global conf_threshold

    st.title("ğŸ¦ åŸºäºYOLOçš„åŠ¨ç‰©è¯†åˆ«ç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.markdown('<h1 class="sidebar-title">âš™ï¸ æ§åˆ¶é¢æ¿</h1>', unsafe_allow_html=True)

        # æ¨¡å‹é€‰æ‹©
        model_name = st.selectbox(
            "**é€‰æ‹©æ£€æµ‹æ¨¡å‹**",
            list(MODEL_PATHS.keys()),
            index=0,
            help="é€‰æ‹©é¢„è®­ç»ƒçš„YOLOæ¨¡å‹"
        )
        current_model = load_model(model_name)

        # å‚æ•°è®¾ç½®
        st.markdown("---")
        st.markdown("**âš–ï¸ æ£€æµ‹å‚æ•°**")
        conf_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.25, step=0.01)
        iou_threshold = st.slider("IoU é˜ˆå€¼", 0.0, 1.0, 0.5, step=0.01)

        # è®¾å¤‡è®¾ç½®
        st.markdown("---")
        st.markdown("**ğŸ“· è¾“å…¥æºè®¾ç½®**")
        camera_devices = ["é»˜è®¤æ‘„åƒå¤´", "å¤–éƒ¨è®¾å¤‡1", "å¤–éƒ¨è®¾å¤‡2"]
        selected_camera = st.selectbox("è§†é¢‘è¾“å…¥æº", camera_devices)

        # åŠŸèƒ½å¯¼èˆª
        st.markdown("---")
        st.markdown("**ğŸ¯ æ£€æµ‹æ¨¡å¼**")
        task = st.radio("", ["å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹", "å®æ—¶æ£€æµ‹"], index=0)

    # ä¸»å†…å®¹åŒºåŸŸ
    with st.container():

        if task == "å›¾ç‰‡æ£€æµ‹":
            image_detection()

        elif task == "è§†é¢‘æ£€æµ‹":
            video_detection()

        elif task == "å®æ—¶æ£€æµ‹":
            real_time_detection()

def model_train():
    # é¡µé¢è®¾ç½®
    # st.set_page_config(page_title="YOLOæ¨¡å‹è®­ç»ƒå¹³å°", layout="wide")

    # æ ‡é¢˜
    st.title("åŸºäºYOLOçš„åŠ¨ç‰©è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
    st.markdown("---")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'training' not in st.session_state:
        st.session_state.training = False
    if 'process' not in st.session_state:
        st.session_state.process = None
    if 'selected_dataset' not in st.session_state:
        st.session_state.selected_dataset = None
    if 'dataset_stats' not in st.session_state:
        st.session_state.dataset_stats = {"train": 0, "val": 0}


    # ä¾§è¾¹æ  - å¯¼èˆª
    st.sidebar.title("å‚æ•°è®¾ç½®")
    page = st.sidebar.radio("é€‰æ‹©é¡µé¢", ["æ•°æ®é›†é…ç½®", "æ¨¡å‹è®­ç»ƒ", "è®­ç»ƒç›‘æ§"])

    # æ•°æ®é›†é…ç½®é¡µé¢
    if page == "æ•°æ®é›†é…ç½®":
        with st.container():
            st.markdown('<div class="dynamic-border">', unsafe_allow_html=True)
            st.header("ğŸ“ æ•°æ®é›†é…ç½®")

            # æ•°æ®é›†ä¸Šä¼ éƒ¨åˆ†
            with st.expander("ä¸Šä¼ æ•°æ®é›†", expanded=True):
                uploaded_file = st.file_uploader("ä¸Šä¼ ZIPæ ¼å¼çš„æ•°æ®é›†", type=["zip"])

                if uploaded_file is not None:
                    # åˆ›å»ºä¸´æ—¶ç›®å½•
                    temp_dir = "temp_dataset"
                    os.makedirs(temp_dir, exist_ok=True)

                    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                    zip_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(zip_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    # è§£å‹æ–‡ä»¶
                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)

                    # æ£€æŸ¥YOLOæ ¼å¼
                    st.info("æ£€æŸ¥æ•°æ®é›†ç»“æ„...")
                    required_folders = ["images", "labels"]
                    required_splits = ["train", "val"]

                    valid_structure = True
                    for folder in required_folders:
                        folder_path = os.path.join(temp_dir, folder)
                        if not os.path.exists(folder_path):
                            valid_structure = False
                            st.error(f"âŒ ç¼ºå°‘ {folder} æ–‡ä»¶å¤¹")
                            break
                        for split in required_splits:
                            split_path = os.path.join(folder_path, split)
                            if not os.path.exists(split_path):
                                valid_structure = False
                                st.error(f"âŒ åœ¨ {folder} ä¸­ç¼ºå°‘ {split} å­æ–‡ä»¶å¤¹")
                                break

                    if valid_structure:
                        st.success("âœ… æ•°æ®é›†ç»“æ„éªŒè¯é€šè¿‡ (YOLOæ ¼å¼)")

                        # è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
                        train_images = len(os.listdir(os.path.join(temp_dir, "images", "train")))
                        val_images = len(os.listdir(os.path.join(temp_dir, "images", "val")))
                        st.session_state.dataset_stats = {"train": train_images, "val": val_images}

                        # æ˜¾ç¤ºåŠ¨æ€ç»Ÿè®¡ä¿¡æ¯
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("è®­ç»ƒå›¾åƒæ•°é‡", train_images)
                        with col2:
                            st.metric("éªŒè¯å›¾åƒæ•°é‡", val_images)

                        # ä¿å­˜æ•°æ®é›†é€‰é¡¹
                        dataset_name = st.text_input("è¾“å…¥æ•°æ®é›†åç§°", "my_dataset")
                        if st.button("ğŸ’¾ ä¿å­˜æ•°æ®é›†"):
                            if dataset_name:
                                dataset_dir = os.path.join("datasets", dataset_name)
                                os.makedirs(dataset_dir, exist_ok=True)

                                # ç§»åŠ¨æ–‡ä»¶
                                for item in os.listdir(temp_dir):
                                    s = os.path.join(temp_dir, item)
                                    d = os.path.join(dataset_dir, item)
                                    if os.path.isdir(s):
                                        shutil.copytree(s, d, dirs_exist_ok=True)
                                    else:
                                        shutil.copy2(s, d)

                                st.success(f"ğŸ‰ æ•°æ®é›† '{dataset_name}' å·²ä¿å­˜!")
                                st.session_state.selected_dataset = dataset_name

                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                shutil.rmtree(temp_dir)
            st.markdown('</div>', unsafe_allow_html=True)

    # # æ¨¡å‹è®­ç»ƒé¡µé¢
    elif page == "æ¨¡å‹è®­ç»ƒ":
        with st.container():
            st.markdown('<div class="dynamic-border">', unsafe_allow_html=True)
            st.header("âš™ï¸ æ¨¡å‹è®­ç»ƒé…ç½®")

            # é€‰æ‹©æ•°æ®é›†éƒ¨åˆ†
            dataset_dir = "datasets"
            if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:
                datasets = os.listdir(dataset_dir)
                selected_dataset = st.selectbox(
                    "é€‰æ‹©æ•°æ®é›†",
                    datasets,
                    index=datasets.index(
                        st.session_state.selected_dataset) if st.session_state.selected_dataset in datasets else 0
                )

                # æ˜¾ç¤ºåŠ¨æ€æ•°æ®é›†ä¿¡æ¯
                with st.expander("æ•°æ®é›†ä¿¡æ¯", expanded=True):
                    dataset_path = os.path.join(dataset_dir, selected_dataset)
                    if os.path.exists(dataset_path):
                        train_images = len(os.listdir(os.path.join(dataset_path, "images", "train")))
                        val_images = len(os.listdir(os.path.join(dataset_path, "images", "val")))

                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("è®­ç»ƒå›¾åƒæ•°é‡", train_images)
                        with col2:
                            st.metric("éªŒè¯å›¾åƒæ•°é‡", val_images)
                    else:
                        st.warning("æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨")

                # åŠ¨æ€æ¨¡å‹é…ç½®éƒ¨åˆ†
                with st.expander("æ¨¡å‹é…ç½®", expanded=True):
                    col1, col2 = st.columns(2)

                    with col1:
                        model_size = st.selectbox("æ¨¡å‹å°ºå¯¸",
                                                  ["nano (n)", "small (s)", "medium (m)", "large (l)", "xlarge (x)"],
                                                  index=1)
                        epochs = st.slider("è®­ç»ƒè½®æ¬¡ (epochs)", min_value=1, max_value=500, value=100)
                        batch_size = st.selectbox("æ‰¹æ¬¡å¤§å° (batch size)", [4, 8, 16, 32, 64], index=1)

                    with col2:
                        img_size = st.selectbox("å›¾åƒå°ºå¯¸ (image size)", [320, 416, 512, 640], index=3)
                        learning_rate = st.slider("å­¦ä¹ ç‡ (learning rate)", min_value=0.0001, max_value=0.1, value=0.01,
                                                  step=0.001, format="%.3f")
                        patience = st.number_input("æ—©åœè€å¿ƒå€¼ (patience)", min_value=1, value=50)

                # åŠ¨æ€é«˜çº§é€‰é¡¹éƒ¨åˆ†
                with st.expander("é«˜çº§é€‰é¡¹"):
                    col3, col4 = st.columns(2)

                    with col3:
                        optimizer = st.selectbox("ä¼˜åŒ–å™¨", ["SGD", "Adam", "AdamW"], index=0)
                        weight_decay = st.number_input("æƒé‡è¡°å‡ (weight decay)", min_value=0.0, value=0.0005,
                                                       step=0.0001, format="%.4f")

                    with col4:
                        augment = st.checkbox("æ•°æ®å¢å¼º", value=True)
                        save_period = st.number_input("ä¿å­˜é—´éš” (save period)", min_value=1, value=10)

                # åŠ¨æ€è®­ç»ƒæ§åˆ¶éƒ¨åˆ†
                with st.expander("è®­ç»ƒæ§åˆ¶", expanded=True):
                    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒ") and not st.session_state.training:
                        st.session_state.training = True

                        # åˆ›å»ºè¾“å‡ºç›®å½•
                        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
                        output_dir = os.path.join("runs", f"train_{current_time}")
                        os.makedirs(output_dir, exist_ok=True)

                        # æ˜¾ç¤ºåŠ¨æ€è®­ç»ƒä¿¡æ¯
                        st.info("è®­ç»ƒé…ç½®ä¿¡æ¯:")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**æ•°æ®é›†:** {selected_dataset}")
                            st.write(f"**æ¨¡å‹å°ºå¯¸:** {model_size}")
                            st.write(f"**è®­ç»ƒè½®æ¬¡:** {epochs}")
                        with col2:
                            st.write(f"**æ‰¹æ¬¡å¤§å°:** {batch_size}")
                            st.write(f"**å›¾åƒå°ºå¯¸:** {img_size}")
                            st.write(f"**å­¦ä¹ ç‡:** {learning_rate}")

                        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for i in range(1, 101):
                            progress_bar.progress(i)
                            status_text.text(f"è®­ç»ƒè¿›åº¦: {i}%")
                            # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„è®­ç»ƒè¿‡ç¨‹

                            # time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒå»¶è¿Ÿ

                        st.session_state.training = False
                        st.success("ğŸ‰ è®­ç»ƒå®Œæˆ!")

                    elif st.session_state.training:
                        st.warning("è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­...")
                        if st.button("ğŸ›‘ åœæ­¢è®­ç»ƒ"):
                            st.session_state.training = False
                            st.experimental_rerun()
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®é›†")
            st.markdown('</div>', unsafe_allow_html=True)
    #
    # # è®­ç»ƒç›‘æ§é¡µé¢
    elif page == "è®­ç»ƒç›‘æ§":
        st.write("demo")
    #     with st.container():
    #         st.markdown('<div class="dynamic-border">', unsafe_allow_html=True)
    #         st.header("ğŸ“Š è®­ç»ƒç›‘æ§")
    #
    #         # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒè¿è¡Œ
    #         runs_dir = "runs"
    #         if os.path.exists(runs_dir) and len(os.listdir(runs_dir)) > 0:
    #             runs = sorted(os.listdir(runs_dir), reverse=True)
    #             selected_run = st.selectbox("é€‰æ‹©è®­ç»ƒè¿è¡Œ", runs)
    #
    #             run_path = os.path.join(runs_dir, selected_run)
    #
    #             # åŠ¨æ€æ˜¾ç¤ºè®­ç»ƒç»“æœ
    #             with st.expander("è®­ç»ƒç»“æœ", expanded=True):
    #                 # æ¨¡æ‹Ÿç»“æœå›¾è¡¨
    #                 col1, col2 = st.columns(2)
    #                 with col1:
    #                     st.line_chart({"æŸå¤±": [0.8, 0.6, 0.4, 0.3, 0.25, 0.2]}, height=300)
    #                     st.caption("è®­ç»ƒæŸå¤±æ›²çº¿")
    #                 with col2:
    #                     st.line_chart({"å‡†ç¡®ç‡": [0.2, 0.4, 0.6, 0.7, 0.75, 0.8]}, height=300)
    #                     st.caption("éªŒè¯å‡†ç¡®ç‡æ›²çº¿")
    #
    #             # åŠ¨æ€æ˜¾ç¤ºè®­ç»ƒæ—¥å¿—
    #             with st.expander("è®­ç»ƒæ—¥å¿—"):
    #                 # æ¨¡æ‹Ÿæ—¥å¿—å†…å®¹
    #                 log_content = """
    # [2023-01-01 10:00:00] è®­ç»ƒå¼€å§‹: yolov8s on my_dataset
    # [2023-01-01 10:05:00] Epoch 1/100 - loss: 0.8 - accuracy: 0.2
    # [2023-01-01 10:10:00] Epoch 10/100 - loss: 0.6 - accuracy: 0.4
    # [2023-01-01 10:15:00] Epoch 20/100 - loss: 0.4 - accuracy: 0.6
    # [2023-01-01 10:20:00] Epoch 30/100 - loss: 0.3 - accuracy: 0.7
    # [2023-01-01 10:25:00] Epoch 40/100 - loss: 0.25 - accuracy: 0.75
    # [2023-01-01 10:30:00] Epoch 50/100 - loss: 0.2 - accuracy: 0.8
    # [2023-01-01 10:35:00] è®­ç»ƒå®Œæˆ - æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨ runs/train_20230101_100000/weights/best.pt
    #                 """
    #                 st.text_area("æ—¥å¿—å†…å®¹", log_content, height=300)
    #         else:
    #             st.warning("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè¿è¡Œ")
    #         st.markdown('</div>', unsafe_allow_html=True)

def main():
    global target_class
    # å¯¼èˆªèœå•
    st.sidebar.markdown('<h1 class="sidebar-title">ğŸ§­ å¯¼èˆªèœå•</h1>', unsafe_allow_html=True)
    page = st.sidebar.radio("",
                          ["æ¨¡å‹é€‰æ‹©ï¼ˆå·²æä¾›ï¼‰", "æ¨¡å‹è‡ªå®šä¹‰ï¼ˆè®­ç»ƒï¼‰"],
                          index=0,
                          format_func=lambda x: "ğŸ” å¿«é€Ÿæ£€æµ‹" if x == "æ¨¡å‹é€‰æ‹©ï¼ˆå·²æä¾›ï¼‰" else "ğŸ› ï¸ æ¨¡å‹è®­ç»ƒ"
                          )

    # å…¨å±€è®¾ç½®åŒºåŸŸï¼ˆæ˜¾ç¤ºåœ¨å¯¼èˆªèœå•ä¸‹æ–¹ï¼‰
    with st.sidebar.expander("âš™ï¸ æ£€æµ‹è®¾ç½®", expanded=True):
        # å•ç±»/å¤šç±»è¯†åˆ«é€‰æ‹©
        detection_mode = st.radio(
            "æ£€æµ‹æ¨¡å¼",
            ["å¤šç±»è¯†åˆ«", "å•ç±»è¯†åˆ«"],
            index=0,
            help="é€‰æ‹©æ˜¯å¦åªæ£€æµ‹ç‰¹å®šç±»åˆ«çš„ç›®æ ‡"
        )

        # ç±»é€‰æ‹©å™¨
        if detection_mode == "å•ç±»è¯†åˆ«":
            # è¿™é‡Œæ›¿æ¢ä¸ºä½ çš„å®é™…ç±»åˆ«åˆ—è¡¨
            class_options = ["cat", "dog", "bird","teddy bear"]
            target_class = st.selectbox(
                "é€‰æ‹©è¦è¯†åˆ«çš„ç›®æ ‡ç±»åˆ«",
                options=class_options,
                index=0
            )
        else: target_class = ["cat", "dog", "bird","teddy bear"]

    if page == "æ¨¡å‹é€‰æ‹©ï¼ˆå·²æä¾›ï¼‰":
        model_usage()
    else:
        model_train()


# è¿è¡Œ Streamlit åº”ç”¨
if __name__ == "__main__":
    main()
